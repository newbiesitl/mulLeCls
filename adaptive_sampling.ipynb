{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from data set\n",
    "from utils.data_utils import jigsaw_toxix_ds_get_df\n",
    "import numpy as np\n",
    "from config import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df = jigsaw_toxix_ds_get_df()\n",
    "comments = df[\"comment_text\"].tolist()\n",
    "comments = [x.replace('\\n', ' ') for x in comments]\n",
    "\n",
    "classes = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "dump_text = '\\n'.join(comments)\n",
    "total_classes = 6\n",
    "class_matrix = df[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]].astype('int')\n",
    "label_matrix = class_matrix.values\n",
    "h_dim = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained w2v...done.\n"
     ]
    }
   ],
   "source": [
    "# load word2vec model\n",
    "import os \n",
    "from config import model_folder\n",
    "from model_factory.embeddings.w2v import w2v_load_from_keyedvectors, build_embedding_layer\n",
    "w2v_name = 'google_keyed_vector_format.bin'\n",
    "model_path = os.path.join(model_folder, w2v_name)\n",
    "print('loading pretrained w2v', end='...')    \n",
    "w2v_model = w2v_load_from_keyedvectors(model_path)\n",
    "vocab = w2v_model.vocab\n",
    "print('done.')\n",
    "word_2_idx = dict(zip(vocab.keys(), range(len(vocab))))\n",
    "max_sent_length = 80\n",
    "trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing data..."
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "import nltk\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "def tokenizer(text, word2idx, max_len=80, total=None):\n",
    "    if total is not None:\n",
    "        text = text[:total]\n",
    "    for sentence_idx in range(len(text)):\n",
    "        sentence = text[sentence_idx]\n",
    "        text[sentence_idx] = nltk.word_tokenize(sentence)\n",
    " \n",
    "    def _sent_to_idx(s, w2i):\n",
    "        for word_idx in range(len(s)):\n",
    "            word = s[word_idx]\n",
    "            idx = w2i.get(word, w2i['null'])\n",
    "            s[word_idx] = idx\n",
    "        return s\n",
    "        \n",
    "    for sentence_idx in range(len(text)):\n",
    "        sentence = text[sentence_idx]\n",
    "        sequence = _sent_to_idx(sentence, word2idx)\n",
    "        text[sentence_idx] = sequence\n",
    "    \n",
    "    text = pad_sequences(text, maxlen=max_len, value=word2idx['null'])   \n",
    "    return text\n",
    "\n",
    "num_samples = 50000\n",
    "print('tokenizing data', end='...')\n",
    "tokenized_sequence = tokenizer(comments, word_2_idx, max_sent_length, total=num_samples)\n",
    "if num_samples is not None:\n",
    "    label_matrix = class_matrix.values[:num_samples]\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes network\n",
    "\n",
    "from model_factory.lstm_mc_dropout import SeqCLS\n",
    "from keras import backend as K\n",
    "\n",
    "def get_new_model(w2v_model):\n",
    "    print('initialize embedding layer', end='...')\n",
    "    embedding_layer = build_embedding_layer(w2v_model, word_2_idx, \n",
    "                                            len(vocab), max_sent_length, trainable)\n",
    "    print('done.')\n",
    "    m = SeqCLS()\n",
    "    m.configure(None, \n",
    "                None, \n",
    "                total_classes, 300, \n",
    "                pretrained_embedding=embedding_layer,\n",
    "                verbose=1,\n",
    "                )\n",
    "    return m\n",
    "\n",
    "\n",
    "            \n",
    "model_copy = get_new_model(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(m, test_X, test_Y, sim=10, threshold = 0.5):\n",
    "    pred_Y, uncertainty_Y = m.predict_with_uncertainty(test_X, sim=sim)\n",
    "    topic_Y = test_Y.T\n",
    "    pred_topic_Y = pred_Y.T\n",
    "    # evaluate performance\n",
    "    \n",
    "    print(threshold)\n",
    "    print(','.join(['sample size','precision','recall', 'prior']))\n",
    "    # print(pred_topic_Y[0].tolist())\n",
    "    for topic_idx in range(len(pred_topic_Y)):\n",
    "        true_topic = topic_Y[topic_idx]\n",
    "        pred_topic = pred_topic_Y[topic_idx]\n",
    "        pred_topic[np.where(pred_topic >= threshold)] = 1\n",
    "        pred_topic[np.where(pred_topic < threshold)] = 0\n",
    "        print('%d, %.2f, %.2f, %.2f' \n",
    "              % (sum(true_topic), \n",
    "                 precision_score(true_topic, pred_topic, average='binary'), \n",
    "                 recall_score(true_topic, pred_topic), \n",
    "                 sum(true_topic)/len(true_topic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "0.259034812883,0.5\n",
      "sample size,precision,recall,prior\n",
      "455, 0.09, 0.53, 0.09\n",
      "41, 0.01, 0.44, 0.01\n",
      "243, 0.05, 0.48, 0.05\n",
      "13, 0.00, 0.77, 0.00\n",
      "209, 0.04, 0.51, 0.04\n",
      "40, 0.01, 0.45, 0.01\n",
      "0.0614055494291,0.5\n",
      "sample size,precision,recall,prior\n",
      "455, 0.00, 0.00, 0.09\n",
      "41, 0.00, 0.00, 0.01\n",
      "243, 0.00, 0.00, 0.05\n",
      "13, 0.00, 0.00, 0.00\n",
      "209, 0.00, 0.00, 0.04\n",
      "40, 0.00, 0.00, 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0733085202926,0.5\n",
      "sample size,precision,recall,prior\n",
      "455, 0.29, 0.01, 0.09\n",
      "41, 0.00, 0.00, 0.01\n",
      "243, 1.00, 0.00, 0.05\n",
      "13, 0.00, 0.00, 0.00\n",
      "209, 0.00, 0.00, 0.04\n",
      "40, 0.00, 0.00, 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.138568742691,0.5\n",
      "sample size,precision,recall,prior\n",
      "455, 0.29, 0.04, 0.09\n",
      "41, 0.00, 0.00, 0.01\n",
      "243, 0.37, 0.04, 0.05\n",
      "13, 0.00, 0.00, 0.00\n",
      "209, 0.50, 0.04, 0.04\n",
      "40, 0.00, 0.00, 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0955973832715,0.5\n",
      "sample size,precision,recall,prior\n",
      "455, 0.62, 0.04, 0.09\n",
      "41, 0.00, 0.00, 0.01\n",
      "243, 0.64, 0.04, 0.05\n",
      "13, 0.00, 0.00, 0.00\n",
      "209, 0.71, 0.02, 0.04\n",
      "40, 0.00, 0.00, 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0997819102574,0.5\n",
      "sample size,precision,recall,prior\n",
      "455, 0.67, 0.07, 0.09\n",
      "41, 0.00, 0.00, 0.01\n",
      "243, 0.67, 0.08, 0.05\n",
      "13, 0.00, 0.00, 0.00\n",
      "209, 0.74, 0.08, 0.04\n",
      "40, 0.00, 0.00, 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.152532349041,0.5\n",
      "sample size,precision,recall,prior\n",
      "455, 0.69, 0.14, 0.09\n",
      "41, 0.50, 0.02, 0.01\n",
      "243, 0.67, 0.14, 0.05\n",
      "13, 0.00, 0.00, 0.00\n",
      "209, 0.68, 0.17, 0.04\n",
      "40, 0.00, 0.00, 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.178650489239,0.5\n",
      "sample size,precision,recall,prior\n",
      "455, 0.63, 0.19, 0.09\n",
      "41, 0.20, 0.02, 0.01\n",
      "243, 0.62, 0.16, 0.05\n",
      "13, 0.00, 0.00, 0.00\n",
      "209, 0.70, 0.18, 0.04\n",
      "40, 0.00, 0.00, 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.171107297787,0.5\n",
      "sample size,precision,recall,prior\n",
      "455, 0.73, 0.22, 0.09\n",
      "41, 0.00, 0.00, 0.01\n",
      "243, 0.71, 0.19, 0.05\n",
      "13, 0.00, 0.00, 0.00\n",
      "209, 0.67, 0.19, 0.04\n",
      "40, 0.00, 0.00, 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pintellect/anaconda3/envs/ml-dev/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# importance sampling\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from sklearn.metrics.classification import precision_score, recall_score\n",
    "\n",
    "batch_size = 5000\n",
    "batch_idx = 0\n",
    "train_test_split = 0.9\n",
    "divider = int(len(tokenized_sequence) * train_test_split)\n",
    "train_X, train_Y = tokenized_sequence[:divider], label_matrix[:divider]\n",
    "test_X, test_Y = tokenized_sequence[divider:], label_matrix[divider:]\n",
    "total_data = train_X.shape[0]\n",
    "sim = 10\n",
    "total_X = []\n",
    "total_Y = []\n",
    "\n",
    "\n",
    "print(batch_size)\n",
    "target_topic_idx = 0\n",
    "\n",
    "while True:\n",
    "    l, r = batch_idx*batch_size, min((batch_idx+1)*batch_size, total_data-1)\n",
    "    if l > r:\n",
    "        batch_idx = 0\n",
    "        break\n",
    "    this_batch_indices = np.array(range(l, r))\n",
    "    selected_batch = train_X[this_batch_indices]\n",
    "#     reset_weights()\n",
    "    if len(total_X) > 0:        \n",
    "        model_copy.fit(\n",
    "            np.array(total_X), \n",
    "            np.array(total_Y), \n",
    "            epochs=20, batch_size=100, verbose=0)\n",
    "    pred_Y, uncertainty_Y = model_copy.predict_with_uncertainty(selected_batch, sim=sim)\n",
    "    \n",
    "\n",
    "    uncertainty_Y_cpy = np.swapaxes(uncertainty_Y, 0, -1)\n",
    "    \n",
    "    for topic_index in range(uncertainty_Y_cpy.shape[0]):\n",
    "        if topic_index == target_topic_idx:\n",
    "            topic_uncertainties = uncertainty_Y_cpy[topic_index]\n",
    "            percentile = np.percentile(topic_uncertainties, 90)\n",
    "            print(percentile, end=',')\n",
    "            selected = np.where(topic_uncertainties > percentile)\n",
    "            selected_batch_indices = this_batch_indices[selected]\n",
    "            selected_X = train_X[selected_batch_indices].tolist()\n",
    "            selected_Y = train_Y[selected_batch_indices].tolist()\n",
    "            total_X += selected_X\n",
    "            total_Y += selected_Y\n",
    "\n",
    "    eval_model(model_copy, test_X, test_Y)\n",
    "    batch_idx += 1\n",
    "\n",
    "    \n",
    "\n",
    "print('Done!')\n",
    "# print(uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection strategy\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from sklearn.metrics.classification import precision_score, recall_score\n",
    "\n",
    "batch_size = 5000\n",
    "batch_idx = 0\n",
    "train_test_split = 0.9\n",
    "divider = int(len(tokenized_sequence) * train_test_split)\n",
    "train_X, train_Y = tokenized_sequence[:divider], label_matrix[:divider]\n",
    "test_X, test_Y = tokenized_sequence[divider:], label_matrix[divider:]\n",
    "total_data = train_X.shape[0]\n",
    "random_selected_idx = np.random.choice(range(total_data), 5000, replace=False)\n",
    "sim = 10\n",
    "\n",
    "model_copy.fit(\n",
    "    train_X[random_selected_idx], \n",
    "    train_Y[random_selected_idx], \n",
    "    epochs=50, batch_size=100, verbose=0)\n",
    "eval_model(model_copy, test_X, test_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
