{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data from data set\n",
    "from utils.data_utils import jigsaw_toxix_ds_get_df\n",
    "import numpy as np\n",
    "from config import *\n",
    "df = jigsaw_toxix_ds_get_df()\n",
    "comments = df[\"comment_text\"].tolist()\n",
    "comments = [x.replace('\\n', ' ') for x in comments]\n",
    "dump_text = '\\n'.join(comments)\n",
    "total_classes = 6\n",
    "class_matrix = df[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]].astype('int')\n",
    "label_matrix = class_matrix.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.embeddings.Embedding object at 0x7f4b493b5198>\n"
     ]
    }
   ],
   "source": [
    "# load word2vec model\n",
    "import os \n",
    "from config import model_folder\n",
    "from model_factory.embeddings.w2v import w2v_load_from_keyedvectors, build_embedding_layer\n",
    "w2v_name = 'google_keyed_vector_format.bin'\n",
    "model_path = os.path.join(model_folder, w2v_name)\n",
    "    \n",
    "w2v_model = w2v_load_from_keyedvectors(model_path)\n",
    "vocab = w2v_model.vocab\n",
    "\n",
    "word_2_idx = dict(zip(vocab.keys(), range(len(vocab))))\n",
    "max_sent_length = 80\n",
    "trainable = False\n",
    "embedding_layer = build_embedding_layer(w2v_model, word_2_idx, len(vocab), max_sent_length, trainable)\n",
    "print(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2658516 2658516 2658516 2658516 2658516 2658516 2658516 2658516 2658516\n 2658516 2658516 2658516 2658516 2658516 2658516 2658516 2658516 2658516\n 2658516 2658516 2658516 2658516 2658516 2658516 2658516 2658516 2658516\n 2658516 2658516 2658516 2658516  568547 1143311 2397901  429497 1629550\n 2607418 1919113 2320490  331338  541011 1470874 1867669 1013302 2658516\n 1184450 1867669 1347733 1094413 2658516 2505038 2698952  139818 2361165\n 2868443 1635598  426198 2018065  202066 1149949 2441904 1024517  897112\n 2658516 2946054 2865648 1366835 1347733   84222 2397901 2771823 1560264\n 2397901 2636520 1397957 1321954  426198 1006383 1673089 2658516]\n<keras.layers.embeddings.Embedding object at 0x7f4b493b5198>\n['__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__ignoreds', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__numpys', '__recursive_saveloads', '__reduce__', '__reduce_ex__', '__repr__', '__scipys', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_adapt_by_suffix', '_load_specials', '_save_specials', '_smart_save', 'accuracy', 'closer_than', 'cosine_similarities', 'distance', 'distances', 'doesnt_match', 'evaluate_word_pairs', 'get_keras_embedding', 'get_vector', 'index2entity', 'index2word', 'init_sims', 'load', 'load_word2vec_format', 'log_accuracy', 'log_evaluate_word_pairs', 'most_similar', 'most_similar_cosmul', 'most_similar_to_given', 'n_similarity', 'rank', 'save', 'save_word2vec_format', 'similar_by_vector', 'similar_by_word', 'similarity', 'similarity_matrix', 'syn0', 'syn0norm', 'vector_size', 'vectors', 'vectors_norm', 'vocab', 'wmdistance', 'word_vec', 'words_closer_than', 'wv']\n3000000\nTrue\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "import nltk\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "\n",
    "def tokenizer(text, word2idx, max_len=80, total=5000):\n",
    "    text = text[:total]\n",
    "    for sentence_idx in range(len(text)):\n",
    "        sentence = text[sentence_idx]\n",
    "        text[sentence_idx] = nltk.word_tokenize(sentence)\n",
    " \n",
    "    def _sent_to_idx(s, w2i):\n",
    "        for word_idx in range(len(s)):\n",
    "            word = s[word_idx]\n",
    "            idx = w2i.get(word, w2i['null'])\n",
    "            s[word_idx] = idx\n",
    "        return s\n",
    "        \n",
    "    for sentence_idx in range(len(text)):\n",
    "        sentence = text[sentence_idx]\n",
    "        sequence = _sent_to_idx(sentence, word2idx)\n",
    "        text[sentence_idx] = sequence\n",
    "    \n",
    "    text = pad_sequences(text, maxlen=max_len, value=word2idx['null'])   \n",
    "    return text\n",
    "\n",
    "\n",
    "tokenized_sequence = tokenizer(comments, word_2_idx, max_sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "from keras import models, layers, objectives\n",
    "h_dim = 300\n",
    "m = models.Sequential()\n",
    "m.add(embedding_layer)\n",
    "m.add(layers.LSTM(\n",
    "    units=h_dim, \n",
    "    return_sequences=False,\n",
    "))\n",
    "m.add(layers.Dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join embeddings with data set dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract embedding column and label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model and test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
